{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER Coref\n",
    "\n",
    "goals:\n",
    "1. implement NER Coref framework - In: Text. Out: FewRel queries.\n",
    "2. Test on re3d\n",
    "\n",
    "note:\n",
    "flair installation:\n",
    "```\n",
    "    pip install --upgrade git+https://github.com/flairNLP/flair.git\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0318 13:03:44.651339 140669276460864 file_utils.py:41] PyTorch version 1.4.0+cu92 available.\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-18 13:04:04,682 loading file /home/akvallapuram/.flair/models/en-ner-conll03-v0.4.pt\n"
     ]
    }
   ],
   "source": [
    "parser = spacy.load(\"en_core_web_sm\", disable=['ner'])\n",
    "\n",
    "# load the NER tagger\n",
    "tagger = SequenceTagger.load('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = Sentence('It is being conducted in full coordination and support of the intra-Syrian talks that will be held by the UN Special Envoy de Mistura in Geneva in February, and in view of the Brussels Conference on Syria and the region which will be hosted by the EU later in the spring. They were able to come to a resolution.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence: \"It is being conducted in full coordination and support of the intra-Syrian talks that will be held by the UN Special Envoy de Mistura in Geneva in February, and in view of the Brussels Conference on Syria and the region which will be hosted by the EU later in the spring. They were able to come to a resolution.\"   [− Tokens: 59  − Token-Labels: \"It is being conducted in full coordination and support of the intra-Syrian <S-MISC> talks that will be held by the UN <S-ORG> Special Envoy <B-PER> de <I-PER> Mistura <E-PER> in Geneva <S-LOC> in February, and in view of the Brussels <B-MISC> Conference <I-MISC> on <I-MISC> Syria <E-MISC> and the region which will be hosted by the EU <S-ORG> later in the spring. They were able to come to a resolution.\"]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run NER over sentence\n",
    "tagger.predict(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62 MISC False\n",
      "106 ORG True\n",
      "117 PER True\n",
      "137 LOC False\n",
      "176 MISC False\n",
      "248 ORG True\n"
     ]
    }
   ],
   "source": [
    "for entity in sent.get_spans('ner'):\n",
    "    print(entity.start_pos, entity.tag, entity.tag in \"PER/ORG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_pairs = combinations(sent.get_spans('ner'), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<MISC-span (12): \"intra-Syrian\">, <ORG-span (20): \"UN\">),\n",
       " (<MISC-span (12): \"intra-Syrian\">, <PER-span (22,23,24): \"Envoy de Mistura\">),\n",
       " (<MISC-span (12): \"intra-Syrian\">, <LOC-span (26): \"Geneva\">),\n",
       " (<MISC-span (12): \"intra-Syrian\">,\n",
       "  <MISC-span (34,35,36,37): \"Brussels Conference on Syria\">),\n",
       " (<MISC-span (12): \"intra-Syrian\">, <ORG-span (47): \"EU\">),\n",
       " (<ORG-span (20): \"UN\">, <PER-span (22,23,24): \"Envoy de Mistura\">),\n",
       " (<ORG-span (20): \"UN\">, <LOC-span (26): \"Geneva\">),\n",
       " (<ORG-span (20): \"UN\">,\n",
       "  <MISC-span (34,35,36,37): \"Brussels Conference on Syria\">),\n",
       " (<ORG-span (20): \"UN\">, <ORG-span (47): \"EU\">),\n",
       " (<PER-span (22,23,24): \"Envoy de Mistura\">, <LOC-span (26): \"Geneva\">),\n",
       " (<PER-span (22,23,24): \"Envoy de Mistura\">,\n",
       "  <MISC-span (34,35,36,37): \"Brussels Conference on Syria\">),\n",
       " (<PER-span (22,23,24): \"Envoy de Mistura\">, <ORG-span (47): \"EU\">),\n",
       " (<LOC-span (26): \"Geneva\">,\n",
       "  <MISC-span (34,35,36,37): \"Brussels Conference on Syria\">),\n",
       " (<LOC-span (26): \"Geneva\">, <ORG-span (47): \"EU\">),\n",
       " (<MISC-span (34,35,36,37): \"Brussels Conference on Syria\">,\n",
       "  <ORG-span (47): \"EU\">)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ent_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# article = 'the US Republican presidential candidate Donald TRUMP'\n",
    "# article = 'The Russian President Vladimir PUTIN'\n",
    "article = 'there is nothing'\n",
    "doc = pos_tagger(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there expl\n",
      "is ROOT\n",
      "nothing attr\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase = Sentence(article)\n",
    "tagger.predict(phrase)\n",
    "phrase.get_spans('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PUTIN"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dep = next(doc.sents)\n",
    "doc[dep.root.i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Vladimir PUTIN',\n",
       " 'start_pos': 22,\n",
       " 'end_pos': 36,\n",
       " 'labels': [PER (0.9984)]}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase.get_spans('ner')[1].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Token in module spacy.tokens.token:\n",
      "\n",
      "class Token(builtins.object)\n",
      " |  An individual token – i.e. a word, punctuation symbol, whitespace,\n",
      " |  etc.\n",
      " |  \n",
      " |  DOCS: https://spacy.io/api/token\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __bytes__(...)\n",
      " |  \n",
      " |  __eq__(self, value, /)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __ge__(self, value, /)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __gt__(self, value, /)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __hash__(self, /)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __le__(self, value, /)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __len__(...)\n",
      " |      The number of unicode characters in the token, i.e. `token.text`.\n",
      " |      \n",
      " |      RETURNS (int): The number of unicode characters in the token.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/token#len\n",
      " |  \n",
      " |  __lt__(self, value, /)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __ne__(self, value, /)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  __reduce__(...)\n",
      " |      helper for pickle\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __str__(self, /)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  __unicode__(...)\n",
      " |  \n",
      " |  check_flag(...)\n",
      " |      Check the value of a boolean flag.\n",
      " |      \n",
      " |      flag_id (int): The ID of the flag attribute.\n",
      " |      RETURNS (bool): Whether the flag is set.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/token#check_flag\n",
      " |  \n",
      " |  get_extension(...) from builtins.type\n",
      " |      Look up a previously registered extension by name.\n",
      " |      \n",
      " |      name (unicode): Name of the extension.\n",
      " |      RETURNS (tuple): A `(default, method, getter, setter)` tuple.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/token#get_extension\n",
      " |  \n",
      " |  has_extension(...) from builtins.type\n",
      " |      Check whether an extension has been registered.\n",
      " |      \n",
      " |      name (unicode): Name of the extension.\n",
      " |      RETURNS (bool): Whether the extension has been registered.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/token#has_extension\n",
      " |  \n",
      " |  is_ancestor(...)\n",
      " |      Check whether this token is a parent, grandparent, etc. of another\n",
      " |      in the dependency tree.\n",
      " |      \n",
      " |      descendant (Token): Another token.\n",
      " |      RETURNS (bool): Whether this token is the ancestor of the descendant.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/token#is_ancestor\n",
      " |  \n",
      " |  nbor(...)\n",
      " |      Get a neighboring token.\n",
      " |      \n",
      " |      i (int): The relative position of the token to get. Defaults to 1.\n",
      " |      RETURNS (Token): The token at position `self.doc[self.i+i]`.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/token#nbor\n",
      " |  \n",
      " |  remove_extension(...) from builtins.type\n",
      " |      Remove a previously registered extension.\n",
      " |      \n",
      " |      name (unicode): Name of the extension.\n",
      " |      RETURNS (tuple): A `(default, method, getter, setter)` tuple of the\n",
      " |          removed extension.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/token#remove_extension\n",
      " |  \n",
      " |  set_extension(...) from builtins.type\n",
      " |      Define a custom attribute which becomes available as `Token._`.\n",
      " |      \n",
      " |      name (unicode): Name of the attribute to set.\n",
      " |      default: Optional default value of the attribute.\n",
      " |      getter (callable): Optional getter function.\n",
      " |      setter (callable): Optional setter function.\n",
      " |      method (callable): Optional method for method extension.\n",
      " |      force (bool): Force overwriting existing attribute.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/token#set_extension\n",
      " |      USAGE: https://spacy.io/usage/processing-pipelines#custom-components-attributes\n",
      " |  \n",
      " |  similarity(...)\n",
      " |      Make a semantic similarity estimate. The default estimate is cosine\n",
      " |      similarity using an average of word vectors.\n",
      " |      \n",
      " |      other (object): The object to compare with. By default, accepts `Doc`,\n",
      " |          `Span`, `Token` and `Lexeme` objects.\n",
      " |      RETURNS (float): A scalar similarity score. Higher is more similar.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/token#similarity\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  ancestors\n",
      " |      A sequence of this token's syntactic ancestors.\n",
      " |      \n",
      " |      YIELDS (Token): A sequence of ancestor tokens such that\n",
      " |          `ancestor.is_ancestor(self)`.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/token#ancestors\n",
      " |  \n",
      " |  children\n",
      " |      A sequence of the token's immediate syntactic children.\n",
      " |      \n",
      " |      YIELDS (Token): A child token such that `child.head==self`.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/token#children\n",
      " |  \n",
      " |  cluster\n",
      " |      RETURNS (int): Brown cluster ID.\n",
      " |  \n",
      " |  conjuncts\n",
      " |      A sequence of coordinated tokens, including the token itself.\n",
      " |      \n",
      " |      RETURNS (tuple): The coordinated tokens.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/token#conjuncts\n",
      " |  \n",
      " |  dep\n",
      " |      RETURNS (uint64): ID of syntactic dependency label.\n",
      " |  \n",
      " |  dep_\n",
      " |      RETURNS (unicode): The syntactic dependency label.\n",
      " |  \n",
      " |  doc\n",
      " |  \n",
      " |  ent_id\n",
      " |      RETURNS (uint64): ID of the entity the token is an instance of,\n",
      " |      if any.\n",
      " |  \n",
      " |  ent_id_\n",
      " |      RETURNS (unicode): ID of the entity the token is an instance of,\n",
      " |      if any.\n",
      " |  \n",
      " |  ent_iob\n",
      " |      IOB code of named entity tag. `1=\"I\", 2=\"O\", 3=\"B\"`. 0 means no tag\n",
      " |      is assigned.\n",
      " |      \n",
      " |      RETURNS (uint64): IOB code of named entity tag.\n",
      " |  \n",
      " |  ent_iob_\n",
      " |      IOB code of named entity tag. \"B\" means the token begins an entity,\n",
      " |      \"I\" means it is inside an entity, \"O\" means it is outside an entity,\n",
      " |      and \"\" means no entity tag is set. \"B\" with an empty ent_type\n",
      " |      means that the token is blocked from further processing by NER.\n",
      " |      \n",
      " |      RETURNS (unicode): IOB code of named entity tag.\n",
      " |  \n",
      " |  ent_kb_id\n",
      " |      RETURNS (uint64): Named entity KB ID.\n",
      " |  \n",
      " |  ent_kb_id_\n",
      " |      RETURNS (unicode): Named entity KB ID.\n",
      " |  \n",
      " |  ent_type\n",
      " |      RETURNS (uint64): Named entity type.\n",
      " |  \n",
      " |  ent_type_\n",
      " |      RETURNS (unicode): Named entity type.\n",
      " |  \n",
      " |  has_vector\n",
      " |      A boolean value indicating whether a word vector is associated with\n",
      " |      the object.\n",
      " |      \n",
      " |      RETURNS (bool): Whether a word vector is associated with the object.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/token#has_vector\n",
      " |  \n",
      " |  head\n",
      " |      The syntactic parent, or \"governor\", of this token.\n",
      " |      \n",
      " |      RETURNS (Token): The token predicted by the parser to be the head of\n",
      " |          the current token.\n",
      " |  \n",
      " |  i\n",
      " |  \n",
      " |  idx\n",
      " |      RETURNS (int): The character offset of the token within the parent\n",
      " |      document.\n",
      " |  \n",
      " |  is_alpha\n",
      " |      RETURNS (bool): Whether the token consists of alpha characters.\n",
      " |      Equivalent to `token.text.isalpha()`.\n",
      " |  \n",
      " |  is_ascii\n",
      " |      RETURNS (bool): Whether the token consists of ASCII characters.\n",
      " |      Equivalent to `[any(ord(c) >= 128 for c in token.text)]`.\n",
      " |  \n",
      " |  is_bracket\n",
      " |      RETURNS (bool): Whether the token is a bracket.\n",
      " |  \n",
      " |  is_currency\n",
      " |      RETURNS (bool): Whether the token is a currency symbol.\n",
      " |  \n",
      " |  is_digit\n",
      " |      RETURNS (bool): Whether the token consists of digits. Equivalent to\n",
      " |      `token.text.isdigit()`.\n",
      " |  \n",
      " |  is_left_punct\n",
      " |      RETURNS (bool): Whether the token is a left punctuation mark.\n",
      " |  \n",
      " |  is_lower\n",
      " |      RETURNS (bool): Whether the token is in lowercase. Equivalent to\n",
      " |      `token.text.islower()`.\n",
      " |  \n",
      " |  is_oov\n",
      " |      RETURNS (bool): Whether the token is out-of-vocabulary.\n",
      " |  \n",
      " |  is_punct\n",
      " |      RETURNS (bool): Whether the token is punctuation.\n",
      " |  \n",
      " |  is_quote\n",
      " |      RETURNS (bool): Whether the token is a quotation mark.\n",
      " |  \n",
      " |  is_right_punct\n",
      " |      RETURNS (bool): Whether the token is a right punctuation mark.\n",
      " |  \n",
      " |  is_sent_start\n",
      " |      A boolean value indicating whether the token starts a sentence.\n",
      " |      `None` if unknown. Defaults to `True` for the first token in the `Doc`.\n",
      " |      \n",
      " |      RETURNS (bool / None): Whether the token starts a sentence.\n",
      " |          None if unknown.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/token#is_sent_start\n",
      " |  \n",
      " |  is_space\n",
      " |      RETURNS (bool): Whether the token consists of whitespace characters.\n",
      " |      Equivalent to `token.text.isspace()`.\n",
      " |  \n",
      " |  is_stop\n",
      " |      RETURNS (bool): Whether the token is a stop word, i.e. part of a\n",
      " |      \"stop list\" defined by the language data.\n",
      " |  \n",
      " |  is_title\n",
      " |      RETURNS (bool): Whether the token is in titlecase. Equivalent to\n",
      " |      `token.text.istitle()`.\n",
      " |  \n",
      " |  is_upper\n",
      " |      RETURNS (bool): Whether the token is in uppercase. Equivalent to\n",
      " |      `token.text.isupper()`\n",
      " |  \n",
      " |  lang\n",
      " |      RETURNS (uint64): ID of the language of the parent document's\n",
      " |      vocabulary.\n",
      " |  \n",
      " |  lang_\n",
      " |      RETURNS (unicode): Language of the parent document's vocabulary,\n",
      " |      e.g. 'en'.\n",
      " |  \n",
      " |  left_edge\n",
      " |      The leftmost token of this token's syntactic descendents.\n",
      " |      \n",
      " |      RETURNS (Token): The first token such that `self.is_ancestor(token)`.\n",
      " |  \n",
      " |  lefts\n",
      " |      The leftward immediate children of the word, in the syntactic\n",
      " |      dependency parse.\n",
      " |      \n",
      " |      YIELDS (Token): A left-child of the token.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/token#lefts\n",
      " |  \n",
      " |  lemma\n",
      " |      RETURNS (uint64): ID of the base form of the word, with no\n",
      " |      inflectional suffixes.\n",
      " |  \n",
      " |  lemma_\n",
      " |      RETURNS (unicode): The token lemma, i.e. the base form of the word,\n",
      " |      with no inflectional suffixes.\n",
      " |  \n",
      " |  lex_id\n",
      " |      RETURNS (int): Sequential ID of the token's lexical type.\n",
      " |  \n",
      " |  like_email\n",
      " |      RETURNS (bool): Whether the token resembles an email address.\n",
      " |  \n",
      " |  like_num\n",
      " |      RETURNS (bool): Whether the token resembles a number, e.g. \"10.9\",\n",
      " |      \"10\", \"ten\", etc.\n",
      " |  \n",
      " |  like_url\n",
      " |      RETURNS (bool): Whether the token resembles a URL.\n",
      " |  \n",
      " |  lower\n",
      " |      RETURNS (uint64): ID of the lowercase token text.\n",
      " |  \n",
      " |  lower_\n",
      " |      RETURNS (unicode): The lowercase token text. Equivalent to\n",
      " |      `Token.text.lower()`.\n",
      " |  \n",
      " |  morph\n",
      " |  \n",
      " |  n_lefts\n",
      " |      The number of leftward immediate children of the word, in the\n",
      " |      syntactic dependency parse.\n",
      " |      \n",
      " |      RETURNS (int): The number of leftward immediate children of the\n",
      " |          word, in the syntactic dependency parse.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/token#n_lefts\n",
      " |  \n",
      " |  n_rights\n",
      " |      The number of rightward immediate children of the word, in the\n",
      " |      syntactic dependency parse.\n",
      " |      \n",
      " |      RETURNS (int): The number of rightward immediate children of the\n",
      " |          word, in the syntactic dependency parse.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/token#n_rights\n",
      " |  \n",
      " |  norm\n",
      " |      RETURNS (uint64): ID of the token's norm, i.e. a normalised form of\n",
      " |      the token text. Usually set in the language's tokenizer exceptions\n",
      " |      or norm exceptions.\n",
      " |  \n",
      " |  norm_\n",
      " |      RETURNS (unicode): The token's norm, i.e. a normalised form of the\n",
      " |      token text. Usually set in the language's tokenizer exceptions or\n",
      " |      norm exceptions.\n",
      " |  \n",
      " |  orth\n",
      " |      RETURNS (uint64): ID of the verbatim text content.\n",
      " |  \n",
      " |  orth_\n",
      " |      RETURNS (unicode): Verbatim text content (identical to\n",
      " |      `Token.text`). Exists mostly for consistency with the other\n",
      " |      attributes.\n",
      " |  \n",
      " |  pos\n",
      " |      RETURNS (uint64): ID of coarse-grained part-of-speech tag.\n",
      " |  \n",
      " |  pos_\n",
      " |      RETURNS (unicode): Coarse-grained part-of-speech tag.\n",
      " |  \n",
      " |  prefix\n",
      " |      RETURNS (uint64): ID of a length-N substring from the start of the\n",
      " |      token. Defaults to `N=1`.\n",
      " |  \n",
      " |  prefix_\n",
      " |      RETURNS (unicode): A length-N substring from the start of the token.\n",
      " |      Defaults to `N=1`.\n",
      " |  \n",
      " |  prob\n",
      " |      RETURNS (float): Smoothed log probability estimate of token type.\n",
      " |  \n",
      " |  rank\n",
      " |      RETURNS (int): Sequential ID of the token's lexical type, used to\n",
      " |      index into tables, e.g. for word vectors.\n",
      " |  \n",
      " |  right_edge\n",
      " |      The rightmost token of this token's syntactic descendents.\n",
      " |      \n",
      " |      RETURNS (Token): The last token such that `self.is_ancestor(token)`.\n",
      " |  \n",
      " |  rights\n",
      " |      The rightward immediate children of the word, in the syntactic\n",
      " |      dependency parse.\n",
      " |      \n",
      " |      YIELDS (Token): A right-child of the token.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/token#rights\n",
      " |  \n",
      " |  sent\n",
      " |      RETURNS (Span): The sentence span that the token is a part of.\n",
      " |  \n",
      " |  sent_start\n",
      " |  \n",
      " |  sentiment\n",
      " |      RETURNS (float): A scalar value indicating the positivity or\n",
      " |      negativity of the token.\n",
      " |  \n",
      " |  shape\n",
      " |      RETURNS (uint64): ID of the token's shape, a transform of the\n",
      " |      tokens's string, to show orthographic features (e.g. \"Xxxx\", \"dd\").\n",
      " |  \n",
      " |  shape_\n",
      " |      RETURNS (unicode): Transform of the tokens's string, to show\n",
      " |      orthographic features. For example, \"Xxxx\" or \"dd\".\n",
      " |  \n",
      " |  string\n",
      " |      Deprecated: Use Token.text_with_ws instead.\n",
      " |  \n",
      " |  subtree\n",
      " |      A sequence containing the token and all the token's syntactic\n",
      " |      descendants.\n",
      " |      \n",
      " |      YIELDS (Token): A descendent token such that\n",
      " |          `self.is_ancestor(descendent) or token == self`.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/token#subtree\n",
      " |  \n",
      " |  suffix\n",
      " |      RETURNS (uint64): ID of a length-N substring from the end of the\n",
      " |      token. Defaults to `N=3`.\n",
      " |  \n",
      " |  suffix_\n",
      " |      RETURNS (unicode): A length-N substring from the end of the token.\n",
      " |      Defaults to `N=3`.\n",
      " |  \n",
      " |  tag\n",
      " |      RETURNS (uint64): ID of fine-grained part-of-speech tag.\n",
      " |  \n",
      " |  tag_\n",
      " |      RETURNS (unicode): Fine-grained part-of-speech tag.\n",
      " |  \n",
      " |  tensor\n",
      " |  \n",
      " |  text\n",
      " |      RETURNS (unicode): The original verbatim text of the token.\n",
      " |  \n",
      " |  text_with_ws\n",
      " |      RETURNS (unicode): The text content of the span (with trailing\n",
      " |      whitespace).\n",
      " |  \n",
      " |  vector\n",
      " |      A real-valued meaning representation.\n",
      " |      \n",
      " |      RETURNS (numpy.ndarray[ndim=1, dtype='float32']): A 1D numpy array\n",
      " |          representing the token's semantics.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/token#vector\n",
      " |  \n",
      " |  vector_norm\n",
      " |      The L2 norm of the token's vector representation.\n",
      " |      \n",
      " |      RETURNS (float): The L2 norm of the vector representation.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/token#vector_norm\n",
      " |  \n",
      " |  vocab\n",
      " |  \n",
      " |  whitespace_\n",
      " |      RETURNS (unicode): The trailing whitespace character, if present.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __pyx_vtable__ = <capsule object NULL>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(type(dep.root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dep.root.idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump PROPN amod\n",
      "' PUNCT dep\n",
      "s NOUN nsubj\n",
      "aim NOUN ROOT\n"
     ]
    }
   ],
   "source": [
    "line = parser(\"Trump' s aim\")\n",
    "for tok in line:\n",
    "    print(tok.text , tok.pos_, tok.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LazyStringSet(set):\n",
    "    \"\"\"\n",
    "        Set of Strings with a lazy\n",
    "        accessor. \n",
    "        \n",
    "        Attributes:\n",
    "            set (set): stores only string \n",
    "            type elementselements.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.set = set()\n",
    "    \n",
    "    def get(self, x):\n",
    "        \"\"\"\n",
    "            if the string x is a subset of\n",
    "            any element present in the set, \n",
    "            that element will be returned.\n",
    "        \"\"\"\n",
    "        assert type(x) == str\n",
    "        for i in self.set:\n",
    "            if x in i:\n",
    "                return i\n",
    "        return None\n",
    "    \n",
    "    def put(self, x):\n",
    "        \"\"\"\n",
    "        Inserts new string element x to set.\n",
    "        Returns True if inserted, otherwise False.\n",
    "        \"\"\"\n",
    "        assert type(x) == str\n",
    "        if self.get(x) is None:\n",
    "            self.set.add(x)\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lss = LazyStringSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Donald Trump'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(lss.put(\"Donald Trump\"))\n",
    "lss.get(\"Trump\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possessive improvements for First Mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ROOT'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser(\"her\")[0].dep_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
