{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from nltk import Tree\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "from transformers import pipeline\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-25 17:20:57,646 loading file /home/akvallapuram/.flair/models/en-ner-conll03-v0.4.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b6bbd13de594cab9cbd8fd71509aae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=230.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# dependency parser, ner and sentiment analysis models\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['ner', 'tagger'])\n",
    "ner_tagger = SequenceTagger.load('ner')\n",
    "sent_analyzer = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence: \"Hillary Duff, the mistress of Bill Clinton, hates Hillary Clinton.\" - 10 Tokens]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dependency parsing and named entity recognition\n",
    "sent = \"Hillary Duff, the mistress of Bill Clinton, hates Hillary Clinton.\"\n",
    "doc = dep_parser(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subtext(sent, e1, e2):\n",
    "    doc = dep_parser(sent)\n",
    "    res = set()\n",
    "    for ent in (e1, e2):\n",
    "        print(ent)\n",
    "        n = len((ent.split(\" \")))\n",
    "        for i in range(len(doc)):\n",
    "            if str(doc[i:i+n]) == ent:\n",
    "                res.update([j for j in range(i, i+n)])\n",
    "                res.update([anc.i for anc in doc[n-1].ancestors])\n",
    "                break\n",
    "    return \" \".join([str(doc[j]) for j in sorted(list(res))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hillary Duff\n",
      "Hillary Clinton\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hillary Duff hates Hillary Clinton'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"Hillary Duff, the mistress of Bill Clinton, hates Hillary Clinton.\"\n",
    "e1 = \"Hillary Duff\"\n",
    "e2 = \"Hillary Clinton\"\n",
    "get_subtext(sent, e1, e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n",
      "[6, 7]\n",
      "[9, 10]\n"
     ]
    }
   ],
   "source": [
    "for ent in ner_sent.get_spans('ner'):\n",
    "    print([t.idx for t in ent.tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                hates                             \n",
      "  ________________|___________________________     \n",
      " |               Duff                         |   \n",
      " |      __________|__________                 |    \n",
      " |     |     |    |       mistress            |   \n",
      " |     |     |    |     _____|________        |    \n",
      " |     |     |    |    |              of      |   \n",
      " |     |     |    |    |              |       |    \n",
      " |     |     |    |    |           Clinton Clinton\n",
      " |     |     |    |    |              |       |    \n",
      " .  Hillary  ,    ,   the            Bill  Hillary\n",
      "\n"
     ]
    }
   ],
   "source": [
    "e = next(iter(doc.sents))\n",
    "to_nltk_tree(e.root).pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duff [hates]\n",
      ", [Duff, hates]\n"
     ]
    }
   ],
   "source": [
    "print(doc[1].text, list(doc[1].ancestors))\n",
    "print(doc[8].text, list(x[8].ancestors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hillary\n",
      "Duff\n",
      ",\n",
      "the\n",
      "mistress\n",
      "of\n",
      "Bill\n",
      "Clinton\n",
      ",\n",
      "hates\n",
      "Hillary\n",
      "Clinton\n",
      ".\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(tok) for tok in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hillary [1, 9]\n",
      "Duff [9]\n",
      ", [1, 9]\n",
      "the [1, 4, 9]\n",
      "mistress [1, 9]\n",
      "of [1, 4, 9]\n",
      "Bill [1, 4, 5, 7, 9]\n",
      "Clinton [1, 4, 5, 9]\n",
      ", [1, 9]\n",
      "hates []\n",
      "Hillary [9, 11]\n",
      "Clinton [9]\n",
      ". [9]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(doc)):\n",
    "    print(doc[i], sorted([a.i for a in list(doc[i].ancestors)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Argument 'other' has incorrect type (expected spacy.tokens.span.Span, got list)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-0aed78fec708>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"hates\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: Argument 'other' has incorrect type (expected spacy.tokens.span.Span, got list)"
     ]
    }
   ],
   "source": [
    "print(str(doc[8:10] == [\",\", \"hates\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = set()\n",
    "x.update([1, 2, 3])\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "from src.modelling import sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26142f186faf47438990c6c3f1a136fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=230.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ts = sentiment.TargetSentiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dep_parser' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-9947e2b80d8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/FYP-19-20/src/modelling/sentiment.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, text, head, tail, return_dict)\u001b[0m\n\u001b[1;32m     71\u001b[0m                     \u001b[0mNote\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0museful\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdebugging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \"\"\"\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0msubtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_subtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtail\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_analyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FYP-19-20/src/modelling/sentiment.py\u001b[0m in \u001b[0;36m_get_subtext\u001b[0;34m(self, text, head, tail)\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mentities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \"\"\"\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdep_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ment\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtail\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dep_parser' is not defined"
     ]
    }
   ],
   "source": [
    "ts.predict(sent, e1, e2, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
