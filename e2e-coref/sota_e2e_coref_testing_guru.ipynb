{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing e2e-coref, current SOTA for Coreference Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "# Used Python 3.6\n",
    "# Can work on mac. If using mojave, please refer to https://stackoverflow.com/questions/52509602/cant-compile-c-program-on-a-mac-after-upgrade-to-mojave.\n",
    "# Also in the requirements.txt change the first line to tensorflow==1.13.1\n",
    "# assumes that the e2e-coref folder is in the project directory\n",
    "import sys\n",
    "sys.path.append(\"..\") #to add the root project directory to the python modules path, so that subdirectories of it can be imported\n",
    "\n",
    "from src.preparation.data_loading import read_dossier, read_news_article\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "document.title='sota_e2e_coref_testing_guru - Jupyter Lab'\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "document.title='sota_e2e_coref_testing_guru - Jupyter Lab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0817 21:18:17.308133 140734788502976 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/GuruSenthil/Documents/ProgrammingProjects/FYP_19_20_Project/FYP-19-20/venv/lib/python3.6/site-packages/sklearn/utils/linear_assignment_.py:21: DeprecationWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  DeprecationWarning)\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/GuruSenthil/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting CUDA_VISIBLE_DEVICES to: \n",
      "Running experiment: -f\n"
     ]
    },
    {
     "ename": "ConfigMissingException",
     "evalue": "'No configuration setting found for key -f'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConfigMissingException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-efeb946f4b34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_from_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCorefModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ProgrammingProjects/FYP_19_20_Project/FYP-19-20/e2e-coref/util.py\u001b[0m in \u001b[0;36minitialize_from_env\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Running experiment: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m   \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyhocon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfigFactory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"experiments.conf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m   \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"log_dir\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmkdirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"log_root\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ProgrammingProjects/FYP_19_20_Project/FYP-19-20/venv/lib/python3.6/site-packages/pyhocon/config_tree.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mUndefinedKey\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ProgrammingProjects/FYP_19_20_Project/FYP-19-20/venv/lib/python3.6/site-packages/pyhocon/config_tree.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtree\u001b[0m \u001b[0mlocated\u001b[0m \u001b[0mat\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \"\"\"\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConfigTree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mUndefinedKey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ProgrammingProjects/FYP_19_20_Project/FYP-19-20/venv/lib/python3.6/site-packages/pyhocon/config_tree.py\u001b[0m in \u001b[0;36m_get\u001b[0;34m(self, key_path, key_index, default)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0melt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mUndefinedKey\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mUndefinedKey\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mConfigMissingException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu\"No configuration setting found for key {key}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mkey_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConfigMissingException\u001b[0m: 'No configuration setting found for key -f'"
     ]
    }
   ],
   "source": [
    "#this library's stuff\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from six.moves import input\n",
    "import tensorflow as tf\n",
    "import coref_model as cm\n",
    "import util\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "def create_example(text):\n",
    "  raw_sentences = sent_tokenize(text)\n",
    "  sentences = [word_tokenize(s) for s in raw_sentences]\n",
    "  speakers = [[\"\" for _ in sentence] for sentence in sentences]\n",
    "  return {\n",
    "    \"doc_key\": \"nw\",\n",
    "    \"clusters\": [],\n",
    "    \"sentences\": sentences,\n",
    "    \"speakers\": speakers,\n",
    "  }\n",
    "\n",
    "def print_predictions(example):\n",
    "  words = util.flatten(example[\"sentences\"])\n",
    "  for cluster in example[\"predicted_clusters\"]:\n",
    "    print(u\"Predicted cluster: {}\".format([\" \".join(words[m[0]:m[1]+1]) for m in cluster]))\n",
    "\n",
    "def make_predictions(text, model):\n",
    "  example = create_example(text)\n",
    "  tensorized_example = model.tensorize_example(example, is_training=False)\n",
    "  feed_dict = {i:t for i,t in zip(model.input_tensors, tensorized_example)}\n",
    "  _, _, _, mention_starts, mention_ends, antecedents, antecedent_scores, head_scores = session.run(model.predictions + [model.head_scores], feed_dict=feed_dict)\n",
    "\n",
    "  predicted_antecedents = model.get_predicted_antecedents(antecedents, antecedent_scores)\n",
    "\n",
    "  example[\"predicted_clusters\"], _ = model.get_predicted_clusters(mention_starts, mention_ends, predicted_antecedents)\n",
    "  example[\"top_spans\"] = zip((int(i) for i in mention_starts), (int(i) for i in mention_ends))\n",
    "  example[\"head_scores\"] = head_scores.tolist()\n",
    "  return example\n",
    "\n",
    "\n",
    "config = util.initialize_from_env()\n",
    "model = cm.CorefModel(config)\n",
    "with tf.Session() as session:\n",
    "    model.restore(session)\n",
    "#     while True:\n",
    "#       text = input(\"Document text: \")\n",
    "#       if len(text) > 0:\n",
    "#         print_predictions(make_predictions(text, model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'This is Janice. She is a cat.'\n",
    "\n",
    "print_predictions(make_predictions(text, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "* Started to test the python code that they used for the paper in Ubuntu - it is very memory intensive - at least 16 GB RAM is recommended\n",
    "* Can compile on mac, but you have to install tensorflow 1.13.1. Might have to set some environment variables to get it to compile also due to Mojave.\n",
    "* You also have to download 1 extra file at ‘https://lil.cs.washington.edu/coref/char_vocab.english.txt’\n",
    "* Takes a couple of minutes to load the pre-trained model, after that it’s not too slow to run.\n",
    "* Seems to predict too-large entities for each cluster, ex. Predicts 'the unions , which it has accused of an “ illegal work slowdown ” to win leverage in contract talks' as an entity. Technically correct, but it only needs to include ‘the unions’\n",
    "* Not too slow when running on longer pieces of text, the accuracy also seems to be pretty good.\n",
    "* The largest memory-hogging part seems to be the glove word embeddings, we could probably train our own smaller version of them\n",
    "* Currently only works when used as a command line tool, will need to modify the source code a little bit to make it work as an API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
